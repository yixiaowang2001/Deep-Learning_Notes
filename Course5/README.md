# Sequence Models
Coursera course from DeepLearning.AI ([link](https://www.coursera.org/learn/nlp-sequence-models))

<div align="center">

| **Week** |                                              **Note**                                             |                                                 **Code**                                                |              **Status**              |                    **Keywords**                     |
|:--------:|:-------------------------------------------------------------------------------------------------:|:-------------------------------------------------------------------------------------------------------:|:------------------------------------:|:-------------------------------------------------------------------------------------------------------:|
|  week1  | [week1.md](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/note/week1.md) | [W1A1](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W1A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb) / [W1A2](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W1A2/Dinosaurus_Island_Character_level_language_model.ipynb) / [W1A3](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W1A3/Improvise_a_Jazz_Solo_with_an_LSTM_Network_v4.ipynb) | ![pb1](https://progress-bar.dev/100) | RNN, Vanishing Graidents, GRU, LSTM, Bidirectional RNN, Deep RNN |
|  week2  | [week2.md](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/note/week2.md) | [W2A1](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W2A1/Building_a_Recurrent_Neural_Network_Step_by_Step.ipynb) / [W2A2](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W2A2/Operations_on_word_vectors_v2a.ipynb) | ![pb2](https://progress-bar.dev/100) | Word Embeddings, Word2Vec, Negative Sampling, GloVe Word Vectors |
|  week3  | [week3.md](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/note/week3.md) | [W3A1](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W3A1/Neural_machine_translation_with_attention_v4a.ipynb) / [W3A2](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W3A2/Trigger_word_detection_v2a.ipynb) | ![pb3](https://progress-bar.dev/100) | Beam Search, Bleu Score, Attention Model |
|  week4  | [week4.md](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/note/week4.md) | [W4A1](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W4A1/C5_W4_A1_Transformer_Subclass_v1.ipynb) / [W4L1](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W4L1/Embedding_plus_Positional_encoding.ipynb) / [W4L2](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W4L2/Transformer_application_Named_Entity_Recognition.ipynb) / [W4L3](https://github.com/yixiaowang2001/Deep-Learning_Notes/blob/main/Course5/code/W4L3/QA_dataset.ipynb) | ![pb4](https://progress-bar.dev/100) | Transformer (Self-Attention, Multi-headed Attention) |

</div>